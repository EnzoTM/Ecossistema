Gene:
    De alguma forma o gene tem que manter todas as informações da rede neural.

    Um gene será divido em sessões, sendo cada uma delas uma camada da rede neural.

    Dentro de cada sessão vamos ter o id do neuronio, seguido pelo seu bias, seguido por todos os ids e pesos dos neuronios que ele está conectado.

    Exemplo:
    Layer: 0
    *Neuron: 0. Links: 2 (0.3) 
    *Neuron: 1. Links: 2 (0.2) 

    Layer: 1
    *Neuron: 2. Links: 3 (2.2) 

    Layer: 2
    *Neuron: 3. Links: 

    O gene seria da forma:
    [
        [[neuronio_id, b, link_neuronio_id, link_peso], [neuronio_id, b, link_neuronio_id, link_peso]], #primeira camada 
        [[neuronio_id, b, link_neuronio_id, link_peso]], #segunda camada
        [[neuronio_id, b]] #terceira camada
    ]

    Logo, seria: (todos os bias são zero, entao deixei bomo "b" para ficar mais vizível)
    [
        [[0, b, 2, 0.3], [1, b, 2, 0.2]], #primeira camada 
        [[2, b, 3, 2.2]], #segunda camada
        [[3, b]] #terceira camada
    ]

Rede Neural:
    model1 = NeuralNetwork()

    #input layer
    for i in range(2):
        model1.add_neuron(0, [], bias=0)

    #single neuron hidden layer
    model1.add_neuron(1, [], bias=0)

    #output layer
    model1.add_neuron(2, [], bias=0)

    model1.add_link(0, [Link(model1.search_neuron(2), 0.3)])
    model1.add_link(1, [Link(model1.search_neuron(2), 0.2)])
    model1.add_link(2, [Link(model1.search_neuron(3), 2)])  

    print(model1.predict([1, 2]))

    gene = [
        [[0, 0, 2, 0.3], [1, 0, 2, 0.2]],
        [[2, 0, 3, 2]],
        [[3, 0]]
    ]

    model2 = NeuralNetwork()

    model2.CreateNetwrok(gene)

    print(model2.predict([1, 2]))

isso dai é um código em python que mostra as duas formas que se tem de cirar a rede neural

gene = [
    [[[0, 0], [2, 0.3]], [[1, 0], [2, 0.2]]],
    [[[2, 0], [3, 2]]],
    [[[3, 0]]]
]